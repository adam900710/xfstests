#! /bin/bash
# FS QA Test 200
#
# Basic btrfs inband dedup test
#
#-----------------------------------------------------------------------
# Copyright (c) 2016 Fujitsu.  All Rights Reserved.
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it would be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write the Free Software Foundation,
# Inc.,  51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
#-----------------------------------------------------------------------
#

seq=`basename $0`
seqres=$RESULT_DIR/$seq
echo "QA output created by $seq"

here=`pwd`
tmp=/tmp/$$
status=1	# failure is the default!
trap "_cleanup; exit \$status" 0 1 2 3 15

_cleanup()
{
	cd /
	rm -f $tmp.*
}

# get standard environment, filters and checks
. ./common/rc
. ./common/filter
. ./common/defrag

# remove previous $seqres.full before test
rm -f $seqres.full

# real QA test starts here

_supported_fs btrfs
_supported_os Linux
_require_scratch
_require_btrfs_subcommand dedup
_require_btrfs_fs_feature dedup
_require_btrfs_mkfs_feature dedup

# File size is twice the maximum file extent of btrfs
# So even fallbacked to non-dedup, it will have at least 2 extents
file_size=256m

_scratch_mkfs "-O dedup" >> $seqres.full 2>&1
_scratch_mount

do_dedup_test()
{
	backend=$1
	dedup_bs=$2

	_run_btrfs_util_prog dedup enable -s $backend -b $dedup_bs $SCRATCH_MNT
	# do sync write to ensure dedup hash is added into dedup pool
	$XFS_IO_PROG -f -c "pwrite -b $dedup_bs 0 $dedup_bs" -c "fsync"\
		$SCRATCH_MNT/initial_block | _filter_xfs_io

	# do sync write to ensure we can get stable fiemap later
	$XFS_IO_PROG -f -c "pwrite -b $dedup_bs 0 $file_size" -c "fsync"\
		$SCRATCH_MNT/real_file | _filter_xfs_io

	# Test if real_file is de-duplicated
	nr_uniq_extents=$(_extent_count_uniq $SCRATCH_MNT/real_file)
	nr_total_extents=$(_extent_count $SCRATCH_MNT/real_file)

	echo "uniq/total: $nr_uniq_extents/$nr_total_extents" >> $seqres.full
	# Allow a small amount of dedup miss, as commit interval or
	# memory pressure may break a dedup_bs block and cause
	# small extent which won't go through dedup routine
	_within_tolerance "number of uniq extents" $nr_uniq_extents \
		$nr_total_extents $(($nr_total_extents - 1)) 5%

	# Also check the md5sum to ensure data is not corrupted
	md5=$(_md5_checksum $SCRATCH_MNT/real_file)
	echo "md5sum: $md5"
}

# Test inmemory dedup first, use 64K dedup bs to keep compatibility
# with 64K page size
do_dedup_test inmemory 64K

# Test ondisk backend, and re-enable function
do_dedup_test ondisk 64K

# Test 128K(default) dedup bs
do_dedup_test inmemory 128K
do_dedup_test ondisk 128K

# Check dedup disable
_run_btrfs_util_prog dedup disable $SCRATCH_MNT

# success, all done
status=0
exit
